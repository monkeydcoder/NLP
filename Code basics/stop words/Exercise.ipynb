{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bfea58-6eec-4e90-99dd-8fa45d089673",
   "metadata": {},
   "source": [
    "# Stop Words: Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f2d991-5639-42fe-b1ab-75a4724984ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy and load the model\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc7632-dc4e-4c8b-b0bc-4459c9f812cd",
   "metadata": {},
   "source": [
    "<b> Exercise1: </b>\n",
    "\n",
    "From a Given Text, Count the number of stop words in it.\n",
    "Print the percentage of stop word tokens compared to all tokens in a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4f6d21-4d7b-4b7a-bd88-0ae6c4352aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stop words in the given question are : 40\n",
      "Percentage of Stop words presented in the given text: 25.0 %\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Thor: Love and Thunder is a 2022 American superhero film based on Marvel Comics featuring the character Thor, produced by Marvel Studios and \n",
    "distributed by Walt Disney Studios Motion Pictures. It is the sequel to Thor: Ragnarok (2017) and the 29th film in the Marvel Cinematic Universe (MCU).\n",
    "The film is directed by Taika Waititi, who co-wrote the script with Jennifer Kaytin Robinson, and stars Chris Hemsworth as Thor alongside Christian Bale, Tessa Thompson,\n",
    "Jaimie Alexander, Waititi, Russell Crowe, and Natalie Portman. In the film, Thor attempts to find inner peace, but must return to action and recruit Valkyrie (Thompson),\n",
    "Korg (Waititi), and Jane Foster (Portman)—who is now the Mighty Thor—to stop Gorr the God Butcher (Bale) from eliminating all gods.\n",
    "'''\n",
    "\n",
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "#step2: define the variables to keep track of stopwords count and total words count\n",
    "\n",
    "num_stop_words = 0\n",
    "total_word_count = 0\n",
    "\n",
    "#step3: iterate through all the words in the document\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        num_stop_words = num_stop_words + 1\n",
    "    total_word_count += 1\n",
    "\n",
    "#step4: print the count of stop words\n",
    "\n",
    "print(\"Total number of stop words in the given question are :\", num_stop_words)\n",
    "\n",
    "#step5: print the percentage of stop words compared to total words in the text\n",
    "\n",
    "percentage_stop_words = (num_stop_words/total_word_count)*100\n",
    "print(f\"Percentage of Stop words presented in the given text: {percentage_stop_words} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f1cd7-4fd3-4a06-a882-7e2bc21135d8",
   "metadata": {},
   "source": [
    "<b> Exercise2: </b>\n",
    "\n",
    "* Spacy default implementation considers \"not\" as a stop word. But in some scenarios removing 'not' will completely change the meaning of the statement/text. For Example, consider these two statements:\n",
    "\n",
    "    * - this is a good movie       ----> Positive Statement\n",
    "    * - this is not a good movie   ----> Negative Statement\n",
    "\n",
    "* So, after applying stopwords to those 2 texts, both will return \"good movie\" and does not respect the polarity/sentiments of text.\n",
    "\n",
    "* Now, your task is to remove this stop word \"not\" in spaCy and help in distinguishing the texts.\n",
    "\n",
    "* Hint: GOOGLE IT! Google is your friend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809f5252-24c7-4a44-82e4-a4c1d73b605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Text 1: good movie .\n",
      "Transformed Text 2: not good movie\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove the stopword 'not' in spaCy\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "\n",
    "# Check if 'not' is in the default stop words set\n",
    "if 'not' in STOP_WORDS:\n",
    "    STOP_WORDS.remove('not')\n",
    "\n",
    "''' OR\n",
    "\n",
    "#Step1: remove the stopword 'not' in spacy\n",
    "nlp.vocab['not'].is_stop = False\n",
    "\n",
    "'''\n",
    "\n",
    "# Step 2: Define the preprocessing function\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop]\n",
    "    return \" \".join(no_stop_words)\n",
    "\n",
    "# Step 3: Pass the texts through the preprocess function and print the results\n",
    "text1 = \"this is a good movie.\"\n",
    "text2 = \"this is not a good movie\"\n",
    "\n",
    "transformed_text1 = preprocess(text1)\n",
    "transformed_text2 = preprocess(text2)\n",
    "\n",
    "print(\"Transformed Text 1:\", transformed_text1)\n",
    "print(\"Transformed Text 2:\", transformed_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6081a-efc0-4e3d-b6eb-aecb03dcc8f0",
   "metadata": {},
   "source": [
    "<b>Exercise3:</b>\n",
    "\n",
    "* From a given text, output the most frequently used token after removing all the stop word tokens and punctuations in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a22c9f-bfe6-4344-8d91-181a1c2f7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop]\n",
    "    return \" \".join(no_stop_words)    \n",
    "\n",
    "\n",
    "\n",
    "def preprocess1(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            no_stop_words.append(token.text)\n",
    "    return \" \".join(no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceca9eaa-7bc1-451a-81e5-03d9cae9d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum frequency word: India\n"
     ]
    }
   ],
   "source": [
    "text = ''' The India men's national cricket team, also known as Team India or the Men in Blue, represents India in men's international cricket.\n",
    "It is governed by the Board of Control for Cricket in India (BCCI), and is a Full Member of the International Cricket Council (ICC) with Test,\n",
    "One Day International (ODI) and Twenty20 International (T20I) status. Cricket was introduced to India by British sailors in the 18th century, and the \n",
    "first cricket club was established in 1792. India's national cricket team played its first Test match on 25 June 1932 at Lord's, becoming the sixth team to be\n",
    "granted test cricket status.\n",
    "'''\n",
    "\n",
    "\n",
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "#step2: remove all the stop words and punctuations and store all the remaining tokens in a new list\n",
    "remaining_tokens = []\n",
    "for token in doc:\n",
    "  if token.is_stop or token.is_punct:    #check whether a given token is stop word or punctuations\n",
    "    continue\n",
    "  remaining_tokens.append(token.text)\n",
    "\n",
    "\n",
    "#step3: create a new dictionary and get the frequency of words by iterating through the list which contains stored tokens  \n",
    "frequency_tokens = {}\n",
    "for token in remaining_tokens:\n",
    "  if token != '\\n' and token != ' ':      #As spacy considers new line and empty spaces as seperate token, it's better to ignore them\n",
    "    if token not in frequency_tokens:     #if a particular token occurs for the first time, we initialise it to 1\n",
    "      frequency_tokens[token] = 1\n",
    "    else:\n",
    "      frequency_tokens[token] += 1        #if a partcular token is already present, then increment by 1 based on value already presented\n",
    "\n",
    "\n",
    "#step4: get the maximum frequency word\n",
    "max_freq_word = max(frequency_tokens.keys(), key=(lambda key: frequency_tokens[key]))\n",
    "\n",
    "\n",
    "#step5: finally print the result\n",
    "print(f\"Maximum frequency word: {max_freq_word}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
